{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["Carga de datos y verificación de archivos de datos."],"metadata":{"id":"xhoGi9YrDMqL"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"r2-OWik7jnsX","outputId":"db2461b1-b4fe-4ba5-d105-89f40b70449e"},"outputs":[{"output_type":"stream","name":"stdout","text":["El archivo es un archivo Parquet válido.\n"]}],"source":["import pyarrow.parquet as pq\n","import pandas as pd\n","\n","# Especifica la ruta del archivo Parquet\n","ruta_archivo = \"/content/drive/MyDrive/No Country Proyecto/Data/Clean/Icfes2023_feature_engineering.parquet\"\n","\n","# ver si el archivo es un archivo Parquet\n","try:\n","    pq.ParquetFile(ruta_archivo)\n","    print(\"El archivo es un archivo Parquet válido.\")\n","except Exception as e:\n","    print(\"Error:\", e)"]},{"cell_type":"code","source":["# Lee el archivo Parquet en un DataFrame de pandas\n","df = pd.read_parquet(ruta_archivo)"],"metadata":{"id":"I0MxY1hajwN3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip show scikit-learn"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wYy_oymoNdmA","executionInfo":{"status":"ok","timestamp":1714165307976,"user_tz":180,"elapsed":12614,"user":{"displayName":"Marco Caro","userId":"05900611213953106772"}},"outputId":"4200ae7d-4ac8-445f-b08e-588804d111c8"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Name: scikit-learn\n","Version: 1.2.2\n","Summary: A set of python modules for machine learning and data mining\n","Home-page: http://scikit-learn.org\n","Author: \n","Author-email: \n","License: new BSD\n","Location: /usr/local/lib/python3.10/dist-packages\n","Requires: joblib, numpy, scipy, threadpoolctl\n","Required-by: bigframes, fastai, imbalanced-learn, librosa, mlxtend, qudida, sklearn-pandas, yellowbrick\n"]}]},{"cell_type":"code","source":["print(df.head())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IpxSKpEXjy2m","outputId":"5de91966-1dfd-4ca7-ed7b-87fb34e19480"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["   ESTU_TIPODOCUMENTO ESTU_GENERO  PERIODO ESTU_DEPTO_RESIDE  \\\n","4                  TI           F        1             VALLE   \n","6                  TI           F        1             VALLE   \n","7                  TI           M        1             VALLE   \n","10                 TI           F        1             VALLE   \n","13                 TI           M        1            NARIÑO   \n","\n","   ESTU_MCPIO_RESIDE ESTU_PRESENTACIONSABADO  FAMI_ESTRATOVIVIENDA  \\\n","4               CALI                      No                     2   \n","6         CAICEDONIA                      No                     1   \n","7            JAMUNDÍ                      No                     1   \n","10              CALI                      No                     3   \n","13             PASTO                      No                     4   \n","\n","   FAMI_PERSONASHOGAR  FAMI_CUARTOSHOGAR  \\\n","4               1 a 2                2.0   \n","6               3 a 4                2.0   \n","7               5 a 6                2.0   \n","10              5 a 6                3.0   \n","13              3 a 4                3.0   \n","\n","                     FAMI_EDUCACIONPADRE  ... ESTU_INSE_INDIVIDUAL  \\\n","4   Secundaria (Bachillerato) incompleta  ...                   51   \n","6                    Primaria incompleta  ...                   40   \n","7         Técnica o tecnológica completa  ...                   51   \n","10                   Primaria incompleta  ...                   57   \n","13                             Postgrado  ...                   75   \n","\n","    ESTU_NSE_INDIVIDUAL  ESTU_NSE_ESTABLECIMIENTO CUARTIL_LECTURA_CRITICA  \\\n","4                   3.0                       3.0                      Q2   \n","6                   1.0                       3.0                      Q4   \n","7                   2.0                       3.0                      Q2   \n","10                  3.0                       3.0                      Q4   \n","13                  4.0                       4.0                      Q3   \n","\n","   CUARTIL_MATEMATICAS CUARTIL_C_NATURALES CUARTIL_SOCIALES_CIUDADANAS  \\\n","4                   Q2                  Q1                          Q2   \n","6                   Q3                  Q3                          Q2   \n","7                   Q3                  Q4                          Q3   \n","10                  Q4                  Q4                          Q4   \n","13                  Q3                  Q4                          Q3   \n","\n","   CUARTIL_INGLES ALIMENTACION DEDICACION_ESTUDIO  \n","4              Q3        1-2-2            1-1-1-3  \n","6              Q2        4-4-4            4-1-1-3  \n","7              Q2        2-3-2            4-4-1-4  \n","10             Q3        3-3-3            3-1-1-4  \n","13             Q2        1-1-1            6-1-1-4  \n","\n","[5 rows x 37 columns]\n"]}]},{"cell_type":"code","source":["# Imprimir la lista de columnas y tipos de datos\n","print(df.info())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iIqAd9D2j1tG","outputId":"96a8555e-15b4-4c5f-a6ed-7f2c70fb39e3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'pandas.core.frame.DataFrame'>\n","Index: 180413 entries, 4 to 551147\n","Data columns (total 37 columns):\n"," #   Column                       Non-Null Count   Dtype  \n","---  ------                       --------------   -----  \n"," 0   ESTU_TIPODOCUMENTO           180413 non-null  object \n"," 1   ESTU_GENERO                  180413 non-null  object \n"," 2   PERIODO                      180413 non-null  int64  \n"," 3   ESTU_DEPTO_RESIDE            180413 non-null  object \n"," 4   ESTU_MCPIO_RESIDE            180413 non-null  object \n"," 5   ESTU_PRESENTACIONSABADO      180413 non-null  object \n"," 6   FAMI_ESTRATOVIVIENDA         180413 non-null  int64  \n"," 7   FAMI_PERSONASHOGAR           180413 non-null  object \n"," 8   FAMI_CUARTOSHOGAR            180413 non-null  float64\n"," 9   FAMI_EDUCACIONPADRE          180413 non-null  object \n"," 10  FAMI_EDUCACIONMADRE          180413 non-null  object \n"," 11  FAMI_TRABAJOLABORPADRE       180413 non-null  int64  \n"," 12  FAMI_TRABAJOLABORMADRE       180413 non-null  int64  \n"," 13  COLE_NATURALEZA              180413 non-null  object \n"," 14  COLE_BILINGUE                180413 non-null  object \n"," 15  COLE_CARACTER                180413 non-null  object \n"," 16  COLE_SEDE_PRINCIPAL          180413 non-null  object \n"," 17  COLE_AREA_UBICACION          180413 non-null  object \n"," 18  COLE_JORNADA                 180413 non-null  object \n"," 19  COLE_MCPIO_UBICACION         180413 non-null  object \n"," 20  DESEMP_LECTURA_CRITICA       180413 non-null  int64  \n"," 21  DESEMP_MATEMATICAS           180413 non-null  int64  \n"," 22  DESEMP_C_NATURALES           180413 non-null  int64  \n"," 23  DESEMP_SOCIALES_CIUDADANAS   180413 non-null  int64  \n"," 24  DESEMP_INGLES                180413 non-null  object \n"," 25  PUNT_GLOBAL                  180413 non-null  int64  \n"," 26  PERCENTIL_GLOBAL             180413 non-null  float64\n"," 27  ESTU_INSE_INDIVIDUAL         180413 non-null  int64  \n"," 28  ESTU_NSE_INDIVIDUAL          180413 non-null  float64\n"," 29  ESTU_NSE_ESTABLECIMIENTO     180413 non-null  float64\n"," 30  CUARTIL_LECTURA_CRITICA      180413 non-null  object \n"," 31  CUARTIL_MATEMATICAS          180413 non-null  object \n"," 32  CUARTIL_C_NATURALES          180413 non-null  object \n"," 33  CUARTIL_SOCIALES_CIUDADANAS  180413 non-null  object \n"," 34  CUARTIL_INGLES               180413 non-null  object \n"," 35  ALIMENTACION                 180413 non-null  object \n"," 36  DEDICACION_ESTUDIO           180413 non-null  object \n","dtypes: float64(4), int64(10), object(23)\n","memory usage: 52.3+ MB\n","None\n"]}]},{"cell_type":"markdown","source":["voy a usar el random state 42 en todo el notebook para poder comparar con otros modelos el mismo resultado."],"metadata":{"id":"6N8pn33W1qzQ"}},{"cell_type":"code","source":["import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.ensemble import RandomForestRegressor\n","from sklearn.metrics import mean_squared_error\n","from sklearn.preprocessing import LabelEncoder\n","\n","\n","# Separar la variable objetivo 'PUNT_GLOBAL' del resto de características\n","X = df.drop(columns=['PUNT_GLOBAL'])  # Características\n","y = df['PUNT_GLOBAL']  # Variable objetivo\n","\n","# Codificar las variables categóricas en X\n","X_encoded = pd.get_dummies(X)\n","\n","# Codificar la variable objetivo si es categórica\n","label_encoder = LabelEncoder()\n","y_encoded = label_encoder.fit_transform(y)\n","\n","# Dividir los datos en conjuntos de entrenamiento y prueba\n","X_train_encoded, X_test_encoded, y_train, y_test = train_test_split(X_encoded, y_encoded, test_size=0.2, random_state=42)\n","\n","# Inicializar y entrenar el modelo de Random Forest\n","rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n","rf_model.fit(X_train_encoded, y_train)\n","\n","# Realizar predicciones en el conjunto de prueba\n","y_pred = rf_model.predict(X_test_encoded)\n","\n","# Evaluar el modelo\n","mse = mean_squared_error(y_test, y_pred)\n","print(\"Error Cuadrático Medio:\", mse)\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tFGM73t1Z85Y","outputId":"b0673d43-4c28-43d0-9534-db401c799a71"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Error Cuadrático Medio: 4.258720602499793\n"]}]},{"cell_type":"markdown","source":["LABEL ENCODER MODELO GUARDADO."],"metadata":{"id":"Lg01lGLof50K"}},{"cell_type":"code","source":["import pickle\n","\n","# Guardar el objeto LabelEncoder\n","with open('label_encoder.pkl', 'wb') as f:\n","    pickle.dump(label_encoder, f)\n","\n","# Puedes cargar el LabelEncoder en cualquier momento usando:\n","# with open('label_encoder.pkl', 'rb') as f:\n","#     loaded_label_encoder = pickle.load(f)\n"],"metadata":{"id":"ioV67Hg5fosz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["MODELO RF GUARDADO EN DRIVE USANDO PICKLE."],"metadata":{"id":"o7AcVqM4f7ai"}},{"cell_type":"code","source":["import pickle\n","\n","# Guardar el modelo entrenado\n","with open('random_forest_model_new.pkl', 'wb') as f:\n","    pickle.dump(rf_model, f)\n","\n","# Cargar el modelo en cualquier momento usando:\n","# with open('random_forest_model.pkl', 'rb') as f:\n","#     loaded_model = pickle.load(f)\n"],"metadata":{"id":"Be9V_50Ne5DS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import joblib\n","\n","# Guardar el modelo entrenado\n","joblib.dump(rf_model, 'random_forest_model_icfe.pkl')\n","\n","# Ahora puedes cargar el modelo en cualquier momento usando:\n","# loaded_model = joblib.load('random_forest_model.pkl')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1Z9yolNBkHEM","outputId":"a59248db-464b-44d9-a131-096231183dd7"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['random_forest_model_icfe.pkl']"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["#/content/random_forest_model.pkl"],"metadata":{"id":"REHjW5m6kSpb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# with open('random_forest_model.pkl', 'rb') as f:\n","#     loaded_model = pickle.load(f)"],"metadata":{"id":"oezf1yrCkouj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Random Forest error cuadratico medio 4.259, 20/25 minutos aprox"],"metadata":{"id":"wFAhOvZ8uI8q"}},{"cell_type":"markdown","source":["Regresion lineal."],"metadata":{"id":"WE0Ok7FS_GT8"}},{"cell_type":"code","source":["from sklearn.preprocessing import OneHotEncoder\n","from sklearn.compose import ColumnTransformer\n","from sklearn.linear_model import LinearRegression\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import mean_squared_error\n","\n","# Inicializar OneHotEncoder sin categorías conocidas y con handle_unknown='ignore'\n","encoder = OneHotEncoder(handle_unknown='ignore')\n","\n","# Crear un objeto ColumnTransformer para aplicar la codificación a las columnas categóricas\n","column_transformer = ColumnTransformer([('encoder', encoder, categorical_cols)], remainder='passthrough')\n","\n","# Aplicar la transformación a X_train y X_test\n","X_train_encoded = column_transformer.fit_transform(X_train)\n","X_test_encoded = column_transformer.transform(X_test)\n","\n","# Inicializar y entrenar el modelo de regresión lineal\n","linear_model = LinearRegression()\n","linear_model.fit(X_train_encoded, y_train)\n","\n","# Realizar predicciones en el conjunto de prueba\n","y_pred_linear = linear_model.predict(X_test_encoded)\n","\n","# Calcular el MSE\n","mse_linear = mean_squared_error(y_test, y_pred_linear)\n","print(\"MSE Regresión Lineal:\", mse_linear)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kxMbhtPV_Icj","outputId":"acf5e240-838f-44de-fe44-e741c089dd45"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["MSE Regresión Lineal: 34.101160194690934\n"]}]},{"cell_type":"markdown","source":["MSE lineal: 34.101"],"metadata":{"id":"TrciVW05EPMa"}},{"cell_type":"markdown","source":["Regresión Polinomica"],"metadata":{"id":"6yk5s9TVD63Y"}},{"cell_type":"code","source":["from sklearn.preprocessing import OneHotEncoder\n","from sklearn.compose import ColumnTransformer\n","from sklearn.linear_model import LinearRegression\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import mean_squared_error\n","\n","# Inicializar OneHotEncoder sin categorías conocidas y con handle_unknown='ignore'\n","# esto es porque hay muchas variables categóricas dentro de cada variable categorica\n","encoder = OneHotEncoder(handle_unknown='ignore')\n","\n","# Crear un objeto ColumnTransformer para aplicar la codificación a las columnas categóricas\n","column_transformer = ColumnTransformer([('encoder', encoder, categorical_cols)], remainder='passthrough')\n","\n","# Aplicar la transformación a X_train y X_test\n","X_train_encoded = column_transformer.fit_transform(X_train)\n","X_test_encoded = column_transformer.transform(X_test)\n","\n","\n","# Inicializar y entrenar el modelo de regresión polinómica\n","degree = 2  # Grado del polinomio\n","poly_model = make_pipeline(PolynomialFeatures(degree), LinearRegression())\n","poly_model.fit(X_train_encoded, y_train)\n","\n","# Realizar predicciones en el conjunto de prueba\n","y_pred_poly = poly_model.predict(X_test_encoded)\n","\n","# Calcular el MSE\n","mse_poly = mean_squared_error(y_test, y_pred_poly)\n","print(\"MSE Regresión Polinómica (Grado {}):\".format(degree), mse_poly)\n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vnEo18UYDpVJ","outputId":"216f8a22-b475-4234-f755-c5827d015dda"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["MSE Regresión Polinómica (Grado 2): 11.849037965538459\n"]}]},{"cell_type":"markdown","source":["Regresión lineal y polinomica usando solo variables numéricas"],"metadata":{"id":"t0lrMp7RfOI4"}},{"cell_type":"code","source":["import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LinearRegression\n","from sklearn.preprocessing import PolynomialFeatures\n","from sklearn.metrics import mean_squared_error\n","\n","# Seleccionar solo las columnas numéricas\n","numeric_columns = df.select_dtypes(include=['int64', 'float64'])\n","\n","# Dividir los datos en conjuntos de entrenamiento y prueba\n","X_train, X_test, y_train, y_test = train_test_split(numeric_columns.drop('PUNT_GLOBAL', axis=1), numeric_columns['PUNT_GLOBAL'], test_size=0.2, random_state=42)\n","\n","# Regresión lineal\n","linear_model = LinearRegression()\n","linear_model.fit(X_train, y_train)\n","\n","# Evaluar el modelo lineal\n","linear_predictions = linear_model.predict(X_test)\n","linear_mse = mean_squared_error(y_test, linear_predictions)\n","print(\"Error cuadrático medio (regresión lineal):\", linear_mse)\n","\n","# Regresión polinomial\n","polynomial_features = PolynomialFeatures(degree=2)\n","X_poly = polynomial_features.fit_transform(X_train)\n","polynomial_model = LinearRegression()\n","polynomial_model.fit(X_poly, y_train)\n","\n","# Evaluar el modelo polinomial\n","X_test_poly = polynomial_features.transform(X_test)\n","poly_predictions = polynomial_model.predict(X_test_poly)\n","poly_mse = mean_squared_error(y_test, poly_predictions)\n","print(\"Error cuadrático medio (regresión polinomial):\", poly_mse)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5IJNNR1wfT4c","outputId":"7f7e01b0-4f48-4df7-d074-0f232e1a779d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Error cuadrático medio (regresión lineal): 59.74432581654054\n","Error cuadrático medio (regresión polinomial): 32.601482615225805\n"]}]},{"cell_type":"markdown","source":["Red Neural\n","(solo variables numéricas)\n","\n","\n"],"metadata":{"id":"nqUyuk5Mg2Ko"}},{"cell_type":"markdown","source":["Este código utiliza una red neuronal básica con dos capas ocultas. La primera capa tiene 64 neuronas y la segunda tiene 32. La función de activación utilizada es ReLU en las capas ocultas. La capa de salida no tiene función de activación ya que estamos tratando de predecir un valor numérico.\n","\n","Después de compilar el modelo, lo entrenamos durante 50 épocas utilizando el conjunto de entrenamiento. Luego, evaluamos el modelo utilizando el conjunto de prueba y calculamos el error cuadrático medio."],"metadata":{"id":"_rkGFLt2hRbX"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import tensorflow as tf\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.metrics import mean_squared_error\n","\n","\n","# Seleccionar solo las columnas numéricas y la variable objetivo\n","numeric_columns = df.select_dtypes(include=['int64', 'float64'])\n","X = numeric_columns.drop('PUNT_GLOBAL', axis=1).values\n","y = numeric_columns['PUNT_GLOBAL'].values\n","\n","# Dividir los datos en conjuntos de entrenamiento y prueba\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Normalizar los datos\n","scaler = StandardScaler()\n","X_train_scaled = scaler.fit_transform(X_train)\n","X_test_scaled = scaler.transform(X_test)\n","\n","# Definir el modelo de red neuronal\n","model = tf.keras.models.Sequential([\n","    tf.keras.layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n","    tf.keras.layers.Dense(32, activation='relu'),\n","    tf.keras.layers.Dense(1)\n","])\n","\n","# Compilar el modelo\n","model.compile(optimizer='adam', loss='mean_squared_error')\n","\n","# Entrenar el modelo\n","history = model.fit(X_train_scaled, y_train, epochs=50, batch_size=32, validation_split=0.2)\n","\n","# Evaluar el modelo\n","y_pred = model.predict(X_test_scaled)\n","mse = mean_squared_error(y_test, y_pred)\n","print(\"Error cuadrático medio (red neuronal):\", mse)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"P2paOVdqg4o1","outputId":"00e27553-e5f3-4737-9dd0-877cbeab9f5b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/50\n","3609/3609 [==============================] - 10s 2ms/step - loss: 3774.1670 - val_loss: 53.8669\n","Epoch 2/50\n","3609/3609 [==============================] - 9s 3ms/step - loss: 33.4750 - val_loss: 21.4225\n","Epoch 3/50\n","3609/3609 [==============================] - 10s 3ms/step - loss: 18.5334 - val_loss: 17.0428\n","Epoch 4/50\n","3609/3609 [==============================] - 8s 2ms/step - loss: 15.5531 - val_loss: 19.2817\n","Epoch 5/50\n","3609/3609 [==============================] - 9s 3ms/step - loss: 14.0494 - val_loss: 13.6820\n","Epoch 6/50\n","3609/3609 [==============================] - 10s 3ms/step - loss: 13.1448 - val_loss: 14.0974\n","Epoch 7/50\n","3609/3609 [==============================] - 8s 2ms/step - loss: 12.7077 - val_loss: 12.2336\n","Epoch 8/50\n","3609/3609 [==============================] - 12s 3ms/step - loss: 12.3594 - val_loss: 11.9716\n","Epoch 9/50\n","3609/3609 [==============================] - 9s 3ms/step - loss: 11.9292 - val_loss: 11.7870\n","Epoch 10/50\n","3609/3609 [==============================] - 8s 2ms/step - loss: 11.7744 - val_loss: 11.3142\n","Epoch 11/50\n","3609/3609 [==============================] - 9s 3ms/step - loss: 11.4471 - val_loss: 12.4399\n","Epoch 12/50\n","3609/3609 [==============================] - 10s 3ms/step - loss: 11.3948 - val_loss: 13.6262\n","Epoch 13/50\n","3609/3609 [==============================] - 8s 2ms/step - loss: 11.3395 - val_loss: 12.4316\n","Epoch 14/50\n","3609/3609 [==============================] - 11s 3ms/step - loss: 11.1188 - val_loss: 10.9483\n","Epoch 15/50\n","3609/3609 [==============================] - 9s 3ms/step - loss: 10.9195 - val_loss: 10.7950\n","Epoch 16/50\n","3609/3609 [==============================] - 8s 2ms/step - loss: 10.8508 - val_loss: 12.2146\n","Epoch 17/50\n","3609/3609 [==============================] - 9s 3ms/step - loss: 10.8333 - val_loss: 11.8569\n","Epoch 18/50\n","3609/3609 [==============================] - 12s 3ms/step - loss: 10.7706 - val_loss: 11.0063\n","Epoch 19/50\n","3609/3609 [==============================] - 8s 2ms/step - loss: 10.5835 - val_loss: 15.5180\n","Epoch 20/50\n","3609/3609 [==============================] - 10s 3ms/step - loss: 10.6811 - val_loss: 10.5374\n","Epoch 21/50\n","3609/3609 [==============================] - 10s 3ms/step - loss: 10.3293 - val_loss: 10.4875\n","Epoch 22/50\n","3609/3609 [==============================] - 8s 2ms/step - loss: 10.3707 - val_loss: 15.7190\n","Epoch 23/50\n","3609/3609 [==============================] - 11s 3ms/step - loss: 10.3662 - val_loss: 12.2313\n","Epoch 24/50\n","3609/3609 [==============================] - 17s 5ms/step - loss: 10.2500 - val_loss: 10.2207\n","Epoch 25/50\n","3609/3609 [==============================] - 15s 4ms/step - loss: 10.1369 - val_loss: 17.6713\n","Epoch 26/50\n","3609/3609 [==============================] - 10s 3ms/step - loss: 10.0426 - val_loss: 9.6903\n","Epoch 27/50\n","3609/3609 [==============================] - 11s 3ms/step - loss: 9.9758 - val_loss: 10.6103\n","Epoch 28/50\n","3609/3609 [==============================] - 8s 2ms/step - loss: 9.9971 - val_loss: 11.4036\n","Epoch 29/50\n","3609/3609 [==============================] - 9s 3ms/step - loss: 9.7769 - val_loss: 9.3280\n","Epoch 30/50\n","3609/3609 [==============================] - 10s 3ms/step - loss: 9.7695 - val_loss: 10.0876\n","Epoch 31/50\n","3609/3609 [==============================] - 9s 2ms/step - loss: 9.6541 - val_loss: 10.5830\n","Epoch 32/50\n","3609/3609 [==============================] - 9s 3ms/step - loss: 9.6014 - val_loss: 16.1328\n","Epoch 33/50\n","3609/3609 [==============================] - 10s 3ms/step - loss: 9.5692 - val_loss: 9.4747\n","Epoch 34/50\n","3609/3609 [==============================] - 10s 3ms/step - loss: 9.4702 - val_loss: 9.9094\n","Epoch 35/50\n","3609/3609 [==============================] - 9s 3ms/step - loss: 9.4524 - val_loss: 10.4422\n","Epoch 36/50\n","3609/3609 [==============================] - 10s 3ms/step - loss: 9.4107 - val_loss: 9.5323\n","Epoch 37/50\n","3609/3609 [==============================] - 8s 2ms/step - loss: 9.3083 - val_loss: 11.4282\n","Epoch 38/50\n","3609/3609 [==============================] - 9s 3ms/step - loss: 9.2588 - val_loss: 9.9433\n","Epoch 39/50\n","3609/3609 [==============================] - 10s 3ms/step - loss: 9.1239 - val_loss: 8.8910\n","Epoch 40/50\n","3609/3609 [==============================] - 8s 2ms/step - loss: 9.1866 - val_loss: 9.3162\n","Epoch 41/50\n","3609/3609 [==============================] - 9s 3ms/step - loss: 9.1010 - val_loss: 9.3210\n","Epoch 42/50\n","3609/3609 [==============================] - 9s 3ms/step - loss: 8.9957 - val_loss: 9.2415\n","Epoch 43/50\n","3609/3609 [==============================] - 8s 2ms/step - loss: 8.9647 - val_loss: 11.4599\n","Epoch 44/50\n","3609/3609 [==============================] - 9s 3ms/step - loss: 8.9233 - val_loss: 8.8513\n","Epoch 45/50\n","3609/3609 [==============================] - 9s 3ms/step - loss: 8.8526 - val_loss: 8.5271\n","Epoch 46/50\n","3609/3609 [==============================] - 8s 2ms/step - loss: 8.8640 - val_loss: 8.8436\n","Epoch 47/50\n","3609/3609 [==============================] - 10s 3ms/step - loss: 8.7198 - val_loss: 9.8342\n","Epoch 48/50\n","3609/3609 [==============================] - 10s 3ms/step - loss: 8.7443 - val_loss: 8.7410\n","Epoch 49/50\n","3609/3609 [==============================] - 9s 3ms/step - loss: 8.6645 - val_loss: 8.9542\n","Epoch 50/50\n","3609/3609 [==============================] - 9s 3ms/step - loss: 8.6690 - val_loss: 8.7830\n","1128/1128 [==============================] - 2s 1ms/step\n","Error cuadrático medio (red neuronal): 8.226450656951247\n"]}]},{"cell_type":"markdown","source":["Red Neural con todas las variables, usando incrustaciones de texto (Embeddings)\n","Esto está incompleto, hay que limpiar, ordenar y rellenar los datos."],"metadata":{"id":"q4LGNboii3I6"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow import keras\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.metrics import mean_squared_error\n","\n","# Dividir los datos en características (X) y variable objetivo (y)\n","X = df.drop('PUNT_GLOBAL', axis=1)\n","y = df['PUNT_GLOBAL']\n","\n","# Dividir los datos en características categóricas y numéricas\n","categorical_features = X.select_dtypes(include=['object']).columns.tolist()\n","numeric_features = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n","\n","# Dividir los datos en conjuntos de entrenamiento y prueba\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Convertir variables categóricas en variables dummy (one-hot encoding)\n","X_train_categorical = pd.get_dummies(X_train[categorical_features])\n","X_test_categorical = pd.get_dummies(X_test[categorical_features])\n","\n","# Normalizar las características numéricas\n","scaler = StandardScaler()\n","X_train_numeric_scaled = scaler.fit_transform(X_train[numeric_features])\n","X_test_numeric_scaled = scaler.transform(X_test[numeric_features])\n","\n","\n","keras.backend.clear_session()\n","np.random.seed(42)\n","tf.random.set_seed(42)\n","\n","\n","# Combinar características numéricas y categóricas\n","X_train_processed = np.hstack((X_train_categorical.values, X_train_numeric_scaled))\n","X_test_processed = np.hstack((X_test_categorical.values, X_test_numeric_scaled))\n","\n","# Definir la arquitectura del modelo\n","model = keras.models.Sequential([\n","    keras.layers.Dense(300, activation=\"relu\"),\n","    keras.layers.Dense(100, activation=\"relu\"),\n","    keras.layers.Dense(10, activation=\"softmax\")\n","])\n","\n","# Compilar el modelo\n","model.compile(loss=\"sparse_categorical_crossentropy\",\n","              optimizer=\"sgd\",\n","              metrics=['accuracy'])\n","\n","model.build(input_shape=X_train_processed.shape)\n","model.summary()\n","\n","\n","\n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kYjaO4lKjZSK","outputId":"16886a47-63b9-4899-99cc-2ea8110385ab"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense (Dense)               (144330, 300)             248100    \n","                                                                 \n"," dense_1 (Dense)             (144330, 100)             30100     \n","                                                                 \n"," dense_2 (Dense)             (144330, 10)              1010      \n","                                                                 \n","=================================================================\n","Total params: 279210 (1.07 MB)\n","Trainable params: 279210 (1.07 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n"]}]}]}